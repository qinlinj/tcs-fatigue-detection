{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f532809e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the saved model from the file\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxgboost_model.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m model_file:\n\u001b[0;32m----> 5\u001b[0m     loaded_model \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "#To make predictions on new data, you can load the model from the file and use it\n",
    "import pickle\n",
    "# Load the saved model from the file\n",
    "with open(\"xgboost_model.pkl\", \"rb\") as model_file:\n",
    "    loaded_model = pickle.load(model_file)\n",
    "\n",
    "# Make predictions on new data\n",
    "#new_data_predictions = loaded_model.predict(X_new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "289de596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pydantic import BaseModel\n",
    "import numpy as np\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4800912",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n-pose.pt')\n",
    "\n",
    "\n",
    "class GetKeypoint(BaseModel):\n",
    "    NOSE:           int = 0\n",
    "    LEFT_EYE:       int = 1\n",
    "    RIGHT_EYE:      int = 2\n",
    "    LEFT_EAR:       int = 3\n",
    "    RIGHT_EAR:      int = 4\n",
    "    LEFT_SHOULDER:  int = 5\n",
    "    RIGHT_SHOULDER: int = 6\n",
    "    LEFT_ELBOW:     int = 7\n",
    "    RIGHT_ELBOW:    int = 8\n",
    "    LEFT_WRIST:     int = 9\n",
    "    RIGHT_WRIST:    int = 10\n",
    "    LEFT_HIP:       int = 11\n",
    "    RIGHT_HIP:      int = 12\n",
    "    LEFT_KNEE:      int = 13\n",
    "    RIGHT_KNEE:     int = 14\n",
    "    LEFT_ANKLE:     int = 15\n",
    "    RIGHT_ANKLE:    int = 16\n",
    "        \n",
    "class BodyKeypoints:\n",
    "    def __init__(self, keypoints):\n",
    "        get_keypoint = GetKeypoint()\n",
    "        self.NOSE = keypoints[get_keypoint.NOSE]\n",
    "        self.LEFT_EYE = keypoints[get_keypoint.LEFT_EYE]\n",
    "        self.RIGHT_EYE = keypoints[get_keypoint.RIGHT_EYE]\n",
    "        self.LEFT_EAR = keypoints[get_keypoint.LEFT_EAR]\n",
    "        self.RIGHT_EAR = keypoints[get_keypoint.RIGHT_EAR]\n",
    "        self.LEFT_SHOULDER = keypoints[get_keypoint.LEFT_SHOULDER]\n",
    "        self.RIGHT_SHOULDER = keypoints[get_keypoint.RIGHT_SHOULDER]\n",
    "        self.LEFT_ELBOW = keypoints[get_keypoint.LEFT_ELBOW]\n",
    "        self.RIGHT_ELBOW = keypoints[get_keypoint.RIGHT_ELBOW]\n",
    "        self.LEFT_WRIST = keypoints[get_keypoint.LEFT_WRIST]\n",
    "        self.RIGHT_WRIST = keypoints[get_keypoint.RIGHT_WRIST]\n",
    "        self.LEFT_HIP = keypoints[get_keypoint.LEFT_HIP]\n",
    "        self.RIGHT_HIP = keypoints[get_keypoint.RIGHT_HIP]\n",
    "        self.LEFT_KNEE = keypoints[get_keypoint.LEFT_KNEE]\n",
    "        self.RIGHT_KNEE = keypoints[get_keypoint.RIGHT_KNEE]\n",
    "        self.LEFT_ANKLE = keypoints[get_keypoint.LEFT_ANKLE]\n",
    "        self.RIGHT_ANKLE = keypoints[get_keypoint.RIGHT_ANKLE]\n",
    "        \n",
    "def get_limbs_from_keypoints(keypoints: BodyKeypoints):\n",
    "    limbs = {\n",
    "        \"right_eye&nose\": [keypoints.RIGHT_EYE, keypoints.NOSE],\n",
    "        \"right_eye&right_ear\": [keypoints.RIGHT_EYE, keypoints.RIGHT_EAR],\n",
    "        \"left_eye&nose\": [keypoints.LEFT_EYE, keypoints.NOSE],\n",
    "        \"left_eye&left_ear\": [keypoints.LEFT_EYE, keypoints.LEFT_EAR],\n",
    "        \"right_shoulder&right_elbow\": [keypoints.RIGHT_SHOULDER, keypoints.RIGHT_ELBOW],\n",
    "        \"right_elbow&right_wrist\": [keypoints.RIGHT_ELBOW, keypoints.RIGHT_WRIST],\n",
    "        \"left_shoulder&left_elbow\": [keypoints.LEFT_SHOULDER, keypoints.LEFT_ELBOW],\n",
    "        \"left_elbow&left_wrist\": [keypoints.LEFT_ELBOW, keypoints.LEFT_WRIST],\n",
    "        \"right_hip&right_knee\": [keypoints.RIGHT_HIP, keypoints.RIGHT_KNEE],\n",
    "        \"right_knee&right_ankle\": [keypoints.RIGHT_KNEE, keypoints.RIGHT_ANKLE],\n",
    "        \"left_hip&left_knee\": [keypoints.LEFT_HIP, keypoints.LEFT_KNEE],\n",
    "        \"left_knee&left_ankle\": [keypoints.LEFT_KNEE, keypoints.LEFT_ANKLE],\n",
    "        \"right_shoulder&left_shoulder\": [keypoints.RIGHT_SHOULDER, keypoints.LEFT_SHOULDER],\n",
    "        \"right_hip&left_hip\": [keypoints.RIGHT_HIP, keypoints.LEFT_HIP],\n",
    "        \"right_shoulder&right_hip\": [keypoints.RIGHT_SHOULDER, keypoints.RIGHT_HIP],\n",
    "        \"left_shoulder&left_hip\": [keypoints.LEFT_SHOULDER, keypoints.LEFT_HIP]\n",
    "    }\n",
    "    return limbs\n",
    "\n",
    "body_keypoints_example = BodyKeypoints([[0,0]] * 17)\n",
    "limbs = get_limbs_from_keypoints(body_keypoints_example)\n",
    "def calculate_and_get_angles_as_dict(keypoints_coords, limbs):\n",
    "    angle_information = {}\n",
    "    \n",
    "    for limb_1_name, limb_2_name in adjacent_limbs:\n",
    "        limb_1 = limbs[limb_1_name]\n",
    "        limb_2 = limbs[limb_2_name]\n",
    "        \n",
    "        common_point = None\n",
    "        for point in limb_1:\n",
    "            if any(np.array_equal(point, p) for p in limb_2):\n",
    "                common_point = point\n",
    "                break\n",
    "        \n",
    "        if common_point is None:\n",
    "            continue\n",
    "        \n",
    "        vector_A = np.array(limb_1[1]) - np.array(limb_1[0]) if np.array_equal(limb_1[1], common_point) else np.array(limb_1[0]) - np.array(limb_1[1])\n",
    "        vector_B = np.array(limb_2[1]) - np.array(limb_2[0]) if np.array_equal(limb_2[1], common_point) else np.array(limb_2[0]) - np.array(limb_2[1])\n",
    "        \n",
    "        angle = calculate_angle(vector_A, vector_B)\n",
    "        key = f\"{limb_1_name} - {KEYPOINT_LABELS[np.where((result_keypoint == common_point).all(axis=1))[0][0]]} - {limb_2_name}\"\n",
    "        value = f\"{angle:.1f}Â°\"\n",
    "        \n",
    "        angle_information[key] = value\n",
    "        \n",
    "    return angle_information\n",
    "\n",
    "def find_closest_person_distance(prev_coordinates, current_coordinate):\n",
    "    \"\"\"\n",
    "    Returns the index of the person from the previous frame whose coordinates \n",
    "    are closest to the current_coordinate and the corresponding distance.\n",
    "    \"\"\"\n",
    "    distances = [(idx, np.linalg.norm(np.array(prev_coord) - np.array(current_coordinate)))\n",
    "                 for idx, prev_coord in enumerate(prev_coordinates) if prev_coord is not None]\n",
    "    if distances:\n",
    "        min_distance_item = min(distances, key=lambda x: x[1])\n",
    "        return min_distance_item\n",
    "    return None, float('inf')\n",
    "\n",
    "adjacent_limbs = []\n",
    "\n",
    "selected_limbs = [\n",
    "        \"right_shoulder&right_elbow\",\n",
    "        \"right_elbow&right_wrist\",\n",
    "        \"left_shoulder&left_elbow\",\n",
    "        \"left_elbow&left_wrist\",\n",
    "        \"right_hip&right_knee\",\n",
    "        \"right_knee&right_ankle\",\n",
    "        \"left_hip&left_knee\",\n",
    "        \"left_knee&left_ankle\",\n",
    "        \"right_shoulder&left_shoulder\",\n",
    "        \"right_hip&left_hip\",\n",
    "        \"right_shoulder&right_hip\",\n",
    "        \"left_shoulder&left_hip\"\n",
    "    ]\n",
    "\n",
    "# Generating all possible combinations\n",
    "for i in range(len(selected_limbs)):\n",
    "    for j in range(i + 1, len(selected_limbs)):\n",
    "        limb1 = limbs[selected_limbs[i]]\n",
    "        limb2 = limbs[selected_limbs[j]]\n",
    "        \n",
    "        # Convert keypoints to tuples for comparison\n",
    "        limb1_tuples = [tuple(point) for point in limb1]\n",
    "        limb2_tuples = [tuple(point) for point in limb2]\n",
    "\n",
    "        # Checking if any keypoint in the second limb matches with the keypoints in the first limb\n",
    "        if any(kp in limb1_tuples for kp in limb2_tuples):\n",
    "            adjacent_limbs.append((selected_limbs[i], selected_limbs[j]))\n",
    "\n",
    "KEYPOINT_LABELS = [\n",
    "    \"NOSE\", \"LEFT_EYE\", \"RIGHT_EYE\", \"LEFT_EAR\", \"RIGHT_EAR\", \"LEFT_SHOULDER\",\n",
    "    \"RIGHT_SHOULDER\", \"LEFT_ELBOW\", \"RIGHT_ELBOW\", \"LEFT_WRIST\", \"RIGHT_WRIST\",\n",
    "    \"LEFT_HIP\", \"RIGHT_HIP\", \"LEFT_KNEE\", \"RIGHT_KNEE\", \"LEFT_ANKLE\", \"RIGHT_ANKLE\"\n",
    "]\n",
    "\n",
    "angle_keys = [\n",
    "    'right_shoulder&right_elbow - RIGHT_ELBOW - right_elbow&right_wrist',\n",
    "    'right_shoulder&right_elbow - RIGHT_SHOULDER - right_shoulder&left_shoulder',\n",
    "    'right_shoulder&right_elbow - RIGHT_SHOULDER - right_shoulder&right_hip',\n",
    "    'left_shoulder&left_elbow - LEFT_ELBOW - left_elbow&left_wrist',\n",
    "    'left_shoulder&left_elbow - LEFT_SHOULDER - right_shoulder&left_shoulder',\n",
    "    'left_shoulder&left_elbow - LEFT_SHOULDER - left_shoulder&left_hip',\n",
    "    'right_hip&right_knee - RIGHT_KNEE - right_knee&right_ankle',\n",
    "    'right_hip&right_knee - RIGHT_HIP - right_hip&left_hip',\n",
    "    'right_hip&right_knee - RIGHT_HIP - right_shoulder&right_hip',\n",
    "    'left_hip&left_knee - LEFT_KNEE - left_knee&left_ankle',\n",
    "    'left_hip&left_knee - LEFT_HIP - right_hip&left_hip',\n",
    "    'left_hip&left_knee - LEFT_HIP - left_shoulder&left_hip',\n",
    "    'right_shoulder&left_shoulder - RIGHT_SHOULDER - right_shoulder&right_hip',\n",
    "    'right_shoulder&left_shoulder - LEFT_SHOULDER - left_shoulder&left_hip',\n",
    "    'right_hip&left_hip - RIGHT_HIP - right_shoulder&right_hip',\n",
    "    'right_hip&left_hip - LEFT_HIP - left_shoulder&left_hip'\n",
    "]\n",
    "\n",
    "def calculate_angle(A, B):\n",
    "#     Calculate angle between two vectors A and B.\n",
    "    dot_product = np.dot(A, B)\n",
    "    norm_A = np.linalg.norm(A)\n",
    "    norm_B = np.linalg.norm(B)\n",
    "    return np.arccos(dot_product / (norm_A * norm_B)) * (180/np.pi)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "prev_person_coordinates = [None, None]  # Assuming at most two employees, initialize with None\n",
    "\n",
    "# Create an empty DataFrame with the required columns\n",
    "columns = [\"Employee ID\", \"Frame\", \"Box x\", \"Box y\", \"Box width\", \"Box height\", \"Width-to-height ratio\"] + angle_keys + [\"Fatigue or not\"]\n",
    "# columns = [\"Employee ID\", \"Frame\", \"Box x\", \"Box y\", \"Box width\", \"Box height\", \"Width-to-height ratio\"] + [f\"{keypoint} (x, y)\" for keypoint in KEYPOINT_LABELS] + angle_keys + [\"Fatigue or not\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f948cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the test video file\n",
    "video_capture = cv2.VideoCapture('videos/test_video.mp4')\n",
    "\n",
    "# Create a VideoWriter object to save the annotated video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "output_video = cv2.VideoWriter('videos/annotated_test_video1.avi', fourcc, 30, (frame_width, frame_height))\n",
    "\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Process the frame and extract relevant features\n",
    "    results = model.predict(frame, save=False, conf=0.5)\n",
    "    fatigue_or_not = '0'\n",
    "    # Iterate through results to get bounding boxes and keypoints data\n",
    "    for idx, result in enumerate(results):\n",
    "        keypoints_data = result.keypoints.xy.cpu().numpy() if hasattr(result, 'keypoints') else []\n",
    "        boxes_data = result.boxes.xywh.cpu().numpy() if hasattr(result, 'boxes') else [] # Extract bounding boxes\n",
    "\n",
    "        distances_and_indices = []\n",
    "\n",
    "        # For each person, get the keypoints and determine which \"employee\" they match based on the nose's position\n",
    "        for person_idx, result_keypoint in enumerate(keypoints_data):\n",
    "            if len(result_keypoint) == 0:\n",
    "                continue\n",
    "            get_keypoint = GetKeypoint()\n",
    "            nose_coordinate = tuple(result_keypoint[get_keypoint.NOSE])\n",
    "            matched_person_idx, distance = find_closest_person_distance(prev_person_coordinates, nose_coordinate)\n",
    "            distances_and_indices.append((distance, matched_person_idx, person_idx, result_keypoint))\n",
    "\n",
    "        sorted_matches = sorted(distances_and_indices, key=lambda x: x[0])[:2]\n",
    "\n",
    "        for distance, matched_person_idx, person_idx, result_keypoint in sorted_matches:\n",
    "            if matched_person_idx is not None:\n",
    "                prev_person_coordinates[matched_person_idx] = tuple(result_keypoint[get_keypoint.NOSE])\n",
    "\n",
    "            body_keypoints = BodyKeypoints(result_keypoint)\n",
    "            limbs = get_limbs_from_keypoints(body_keypoints)\n",
    "            angle_info_dict = calculate_and_get_angles_as_dict(result_keypoint, limbs)\n",
    "\n",
    "            # Construct the row data to be appended to the DataFrame\n",
    "            row_data = {\n",
    "                \"Employee ID\": person_idx + 1,\n",
    "                \"Frame\": idx + 1,\n",
    "            }\n",
    "    #         for label, keypoint in zip(KEYPOINT_LABELS, result_keypoint):\n",
    "    #             row_data[f\"{label} (x, y)\"] = tuple(keypoint)\n",
    "            for angle_key in angle_keys:\n",
    "                angle_value = angle_info_dict.get(angle_key, None)\n",
    "                if angle_value:\n",
    "                    angle_value = ''.join([char for char in angle_value if char.isdigit() or char == '.'])\n",
    "                row_data[angle_key] = angle_value\n",
    "\n",
    "            # Include bounding box data for this person\n",
    "            box = boxes_data[person_idx] if len(boxes_data) > person_idx else [None, None, None, None]\n",
    "            # row_data[\"Bounding Box (x, y, w, h)\"] = tuple(box)\n",
    "            row_data[\"Box x\"] = box[0] # The YOLO model frames the object in a box, and x refers to the x-coordinate of the diagonal intersection (geometric center) of the box.\n",
    "            row_data[\"Box y\"] = box[1]\n",
    "            row_data[\"Box width\"] = box[2]\n",
    "            row_data[\"Box height\"] = box[3]\n",
    "            row_data[\"Width-to-height ratio\"] = box[2]/box[3] # The width-to-height ratio of the box\n",
    "\n",
    "\n",
    "            row_data['Fatigue or not'] = fatigue_or_not\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Create a data row for prediction\n",
    "\n",
    "    # Pass the data row to the XGBoost model for prediction\n",
    "    prediction = loaded_model.predict(row_data)\n",
    "\n",
    "    # Overlay the predicted output on the frame\n",
    "    cv2.putText(frame, f\"Prediction: {prediction[0]}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    # Write the annotated frame to the output video\n",
    "    output_video.write(frame)\n",
    "\n",
    "# Release the video capture and writer\n",
    "video_capture.release()\n",
    "output_video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e33abfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec74bfac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2124b661",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
